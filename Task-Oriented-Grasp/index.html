<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriately as they are your "business card" -->
  <meta name="description" content="Task-Oriented Grasp Detection for Robots Based on Deep Learning. Huazhong University of Science and Technology.">
  <meta property="og:title" content="Task-Oriented Grasp Detection for Robots Based on Deep Learning"/>
  <meta property="og:description" content="A deep learning-based framework for robotic grasp detection, enabling robust, task-oriented manipulation. Huazhong University of Science and Technology."/>
  <meta property="og:url" content="https://bbqgwx996.github.io/Task-Oriented-Grasp/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X630-->
  <meta property="og:image" content="static/images/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="Task-Oriented Grasp Detection for Robots Based on Deep Learning">
  <meta name="twitter:description" content="A deep learning-based framework for robotic grasp detection, enabling robust, task-oriented manipulation. Huazhong University of Science and Technology.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="robotics, deep learning, grasp detection, task-oriented, Huazhong University of Science and Technology, object recognition, YOLOv5, GR-ConvNet">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Grasp</title>
  <link rel="icon" type="image/x-icon" href="static/images/personal.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
<!-- 返回Home按钮 -->
<a href="/" style="position: fixed; top: 24px; left: 24px; z-index: 1000; background: #fff; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.08); padding: 8px 18px; font-weight: bold; color: #3273dc; text-decoration: none; border: 1px solid #eaeaea; transition: background 0.2s;">
  ← Home
</a>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Task-Oriented Grasp Detection for Robots Based on Deep Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Weixing Guo</a><sup>*</sup>,</span>
                <span class="author-block">
                  <!--<a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>-->
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Huazhong University of Science and Technology</span>
                    <!--<span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                  </div>

                  <!-- <div class="column has-text-centered">
                    <div class="publication-links">
                          Arxiv PDF link 
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon"> 
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>-->

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/Task-Oriented Grasp Detection for Robots Based on Deep Learning.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                   <!--
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>-->

                <!-- ArXiv abstract Link -->
                <!--
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>-->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!--
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">

        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>-->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Compared with the traditional robotic arm grasping method, the robot grasping method based on deep learning has the advantages of being able to adapt to complex environments, lifting the restrictions on grasping scenes and grasping objects, end-to-end grasping, and autonomously adjusting the network, so as to adapt to a variety of different specific tasks under the same conditions in the general direction, that is, it has many advantages such as task-oriented and task-oriented methods.
Due to the advantages listed above and the specific advantages of some specific fields based on the robot grasping method based on deep learning, this method has received more and more attention and development in the fields of parts assembly, logistics and transportation, and Internet of Things. But for now when applied to complex scenarios, the fusion of object detection and grasping recognition algorithms, as well as the further improvement of the accuracy (AP) and speed (FPS) of the fusion algorithm, are still difficult problems to solve.
Based on the above problems, the research on the robot grasping and recognition algorithm based on deep learning in this paper is mainly implemented in the following specific research contents:
In the study of automatic target recognition and grabbing by robotic arms, this paper builds an experimental platform to achieve automatic recognition and grabbing of target objects by robotic arms. In order to perform target classification detection, this article adopts a deep learning framework and uses the improved YOLOv5 algorithm for target classification detection. This algorithm has high accuracy and real-time performance in target detection. In terms of object grasping final pose detection, this article uses an algorithm based on GR-ConvNet. This algorithm determines the optimal final posture of the robotic arm during the grasping process by analyzing the shape and attitude information of the target object. 
Finally, this paper successfully fuses the code of object classification detection and terminal pose detection to achieve a comprehensive deep learning algorithm. And the experimental test was carried out on the physical prototype, and satisfactory results were obtained. Experimental results show that the task-oriented grasping detection framework combined with deep learning algorithm can quickly and accurately classify and identify target objects, and can analyze the grasping posture and grasping angle. Through this fusion approach, the robotic arm is able to realize the task-oriented function of automatically identifying and grasping target objects. This means that the robotic arm is able to autonomously identify different target objects according to the needs of the task and can accurately grasp their position and angle to complete a specific task.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img class="centered-img" src="static/images/Object prediction in self-maded img database.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Object prediction results on a custom image database.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img class="centered-img" src="static/images/Object prediction in real enviroment.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Object prediction results in a real-world environment.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img class="centered-img" src="static/images/Grasp Position Prediction.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Predicted grasp positions for detected objects.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img class="centered-img" src="static/images/real grasping.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Real-time grasp detection demonstration.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
 <!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">

            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>-->
<!-- End youtube video -->


<!-- Video carousel -->
 <!--
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">

            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">

            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\

            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>-->
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/Task-Oriented Grasp Detection for Robots Based on Deep Learning.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
